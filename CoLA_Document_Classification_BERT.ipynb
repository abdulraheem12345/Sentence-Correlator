{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoLA_Document_Classification_BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvzuIkVZ8+Una9ae4zlCvB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4acc68fc805744889a95bfa51a6014f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1b371e216b9148029ce542d0784e8315",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75a0ec2bf68f4d329ebfca4953a3c90d",
              "IPY_MODEL_57978e2f46554a5192fb860ba74842a0"
            ]
          }
        },
        "1b371e216b9148029ce542d0784e8315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75a0ec2bf68f4d329ebfca4953a3c90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c9c3673fdf7c40e7998265b0a1d3d789",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab70f10de89d47edbb764792aad26690"
          }
        },
        "57978e2f46554a5192fb860ba74842a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_afde831c220448458a141363fd6daa99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 721kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4d17cb74d0b4d329cae9028ed183b76"
          }
        },
        "c9c3673fdf7c40e7998265b0a1d3d789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab70f10de89d47edbb764792aad26690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afde831c220448458a141363fd6daa99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4d17cb74d0b4d329cae9028ed183b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d1f3edf5a73484882b925353df2ce94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_16827436639445daa815cc55bc70171f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5f0cfad9f4b43e28dc227ecc635460a",
              "IPY_MODEL_7774d701bac34236b398dae4ad2a8035"
            ]
          }
        },
        "16827436639445daa815cc55bc70171f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5f0cfad9f4b43e28dc227ecc635460a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c6e8aef18be48a1affecd096e660e9a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cbc15d53077473088e343ec78bced43"
          }
        },
        "7774d701bac34236b398dae4ad2a8035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdafdd63b12a43c5b8aae5465c5cfa0e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [01:59&lt;00:00, 3.61B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d004c66c13ec4186af80d9493f3638b7"
          }
        },
        "6c6e8aef18be48a1affecd096e660e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cbc15d53077473088e343ec78bced43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdafdd63b12a43c5b8aae5465c5cfa0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d004c66c13ec4186af80d9493f3638b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87046de878944b9c9a5e79ae3fbbd919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54f16e9e8c5146458082cf18f3b7ed49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b6e136a6cdef4be287ea7f2f568111e5",
              "IPY_MODEL_af24a11053274475b4d31b4f7719ed6d"
            ]
          }
        },
        "54f16e9e8c5146458082cf18f3b7ed49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6e136a6cdef4be287ea7f2f568111e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f0ac93c4c3a4e5a9ee94a45d62fed45",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c57f8d47a594ffea40fbcd0c78a7821"
          }
        },
        "af24a11053274475b4d31b4f7719ed6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0e6c17c2337a4cd0a0d97e115245849c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 67.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea6f5a23779c4c6182e86ab3a3d41f94"
          }
        },
        "8f0ac93c4c3a4e5a9ee94a45d62fed45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c57f8d47a594ffea40fbcd0c78a7821": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e6c17c2337a4cd0a0d97e115245849c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea6f5a23779c4c6182e86ab3a3d41f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanshiguptaaa/CoLA_Sentence_Classification_BERT/blob/master/CoLA_Document_Classification_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd547pooZrlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Document Classification BERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMVB2VLaY9PK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6979fd1d-03fa-4788-e999-56fdae384dfd"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1yMW5ojZ43o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6353cd26-ac7c-4e30-8660-035ec3f29b07"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjsOX9naA-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "1d8e79fd-d156-4755-ebf4-204f3f2da105"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 4.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 14.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=061b36b8ec0fa40bb021babec3edbf8fbf833d6f3182f408f514b480ac1e3962\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtkMgQEmaPEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "0a6a0311-db7e-4cc9-d5f1-7ee0399e21a1"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=8562bb432cd24fa4d2becbe2bcd9dfb8fe2a3793479d86dd45c989f6a85095da\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LflYZlN3aYSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5caf256a-7783-48f5-9f67-69d91ec11ec2"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O25uSDxqadmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "5c67bba6-b790-421b-ea93-515b8a8e9c80"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_j9f6Qjami9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "06b4f34a-9b53-461a-a4fd-3e2096b6d37e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4574</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Sam may have been being interrogating by the FBI.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4786</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John asks whose book his son likes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4085</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We believe that the directors were present.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2818</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Paula swatted the fly with a cloth.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3782</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They spoil their kids rotten.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3447</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>The professor found some strong evidences of w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>712</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We consider the men all fools.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4471</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Jim does have supported the theory.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3041</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wanda taught the students French.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7741</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dracula thought that he was the Prince of Dark...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "4574            ks08  ...  Sam may have been being interrogating by the FBI.\n",
              "4786            ks08  ...                John asks whose book his son likes.\n",
              "4085            ks08  ...        We believe that the directors were present.\n",
              "2818            l-93  ...                Paula swatted the fly with a cloth.\n",
              "3782            ks08  ...                      They spoil their kids rotten.\n",
              "3447            ks08  ...  The professor found some strong evidences of w...\n",
              "712             bc01  ...                     We consider the men all fools.\n",
              "4471            ks08  ...                Jim does have supported the theory.\n",
              "3041            l-93  ...                  Wanda taught the students French.\n",
              "7741            ad03  ...  Dracula thought that he was the Prince of Dark...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qGFvVN-aqY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1407d6af-60b0-4ac8-8732-1873ca183d23"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>They disappeared their way off the stage.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>You filed every paper without inspecting.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5419</th>\n",
              "      <td>As much of a man is here.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>I reviewed Joe's attempt to find Holly while y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4815</th>\n",
              "      <td>I am not certain about if he will go or not.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "2498          They disappeared their way off the stage.      0\n",
              "1026          You filed every paper without inspecting.      0\n",
              "5419                          As much of a man is here.      0\n",
              "874   I reviewed Joe's attempt to find Holly while y...      0\n",
              "4815       I am not certain about if he will go or not.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxfCoezXau5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Kj3sWgaxan",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "4acc68fc805744889a95bfa51a6014f3",
            "1b371e216b9148029ce542d0784e8315",
            "75a0ec2bf68f4d329ebfca4953a3c90d",
            "57978e2f46554a5192fb860ba74842a0",
            "c9c3673fdf7c40e7998265b0a1d3d789",
            "ab70f10de89d47edbb764792aad26690",
            "afde831c220448458a141363fd6daa99",
            "a4d17cb74d0b4d329cae9028ed183b76"
          ]
        },
        "outputId": "33ab25eb-0d68-4470-873c-7496e6b35d56"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4acc68fc805744889a95bfa51a6014f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8T8JMCma1OD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "64ff34bf-6bce-4910-f4bb-6f2bbb8e32b9"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tm_8o_a54i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "47e15c4e-43cb-4cc7-8020-17f68c7c7d1b"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V80hCa9CbEOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8762e13c-d151-4738-e6a0-db6ef11f8c3f"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU5-MHxHbJrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e8be6854-a3e9-45ea-d9a3-b417f0416959"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6e3Oe-JbNJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcSGMwoFbRAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49qrloHrbTmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2TFSrS7bXI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0jiGwk3batl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4d1f3edf5a73484882b925353df2ce94",
            "16827436639445daa815cc55bc70171f",
            "b5f0cfad9f4b43e28dc227ecc635460a",
            "7774d701bac34236b398dae4ad2a8035",
            "6c6e8aef18be48a1affecd096e660e9a",
            "5cbc15d53077473088e343ec78bced43",
            "cdafdd63b12a43c5b8aae5465c5cfa0e",
            "d004c66c13ec4186af80d9493f3638b7",
            "87046de878944b9c9a5e79ae3fbbd919",
            "54f16e9e8c5146458082cf18f3b7ed49",
            "b6e136a6cdef4be287ea7f2f568111e5",
            "af24a11053274475b4d31b4f7719ed6d",
            "8f0ac93c4c3a4e5a9ee94a45d62fed45",
            "4c57f8d47a594ffea40fbcd0c78a7821",
            "0e6c17c2337a4cd0a0d97e115245849c",
            "ea6f5a23779c4c6182e86ab3a3d41f94"
          ]
        },
        "outputId": "2e901e2b-47a2-472c-b1bb-208a6b078fc4"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d1f3edf5a73484882b925353df2ce94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87046de878944b9c9a5e79ae3fbbd919",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoerOh8qbegW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "9f07cc33-47f0-4523-ded1-30eaad942fc2"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1DfOPFdbkI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hliUyfZsboiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXsLGIi6bvl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUcJnBTsbyoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2YjFs8gb1hh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cd32e00-770c-425c-d577-4e721c1778f0"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.51\n",
            "  Training epcoh took: 0:01:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdFfKyoLb7Sz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "0a750d59-3d1a-433f-cf03-44938bda530f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-N3fVYKcApy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "94291b17-d9e3-45d4-b18e-922645794fd7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNF30U8FcITz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "533dc314-9bd2-464e-959a-bcec0fc30e26"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXTk5LY4cLfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7057d47f-b90e-44d7-8927-d35e89835be3"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy_SFwR8cQ58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4d4a1c71-54f3-43ac-e9a0-b07e6f7ad71e"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-MCNw0cTCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "2cb4609d-6d4b-459d-eb9b-fa4bf813db93"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.049286405809014416,\n",
              " -0.21684543705982773,\n",
              " 0.4040950971038548,\n",
              " 0.23372319715296222,\n",
              " 0.24816038707378335,\n",
              " 0.7410010097502685,\n",
              " 0.6201736729460423,\n",
              " 0.47519096331149147,\n",
              " 0.8320502943378436,\n",
              " 0.8246211251235321,\n",
              " 0.8459051693633014,\n",
              " 0.7419408268023742,\n",
              " 0.8150678894028793,\n",
              " 0.647150228929434,\n",
              " 0.3268228676411533,\n",
              " 0.5056936741642399,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbT-rwHocVqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f02fd26-c042-436c-f327-144cef7c6a76"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh5avgvjcYXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}